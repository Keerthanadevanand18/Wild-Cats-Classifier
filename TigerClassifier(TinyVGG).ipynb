{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57d0f281",
   "metadata": {},
   "source": [
    "# Big Cat Classification using TinyVgg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3242b17b",
   "metadata": {},
   "source": [
    "## Importing necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b43ec8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa24a43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d05b4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86479975",
   "metadata": {},
   "source": [
    "## PreProcessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a17e6e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DIR_PATH = 'tiger_dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666a5462",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for root, dirnames, files in os.walk(DIR_PATH):\n",
    "    print(f\"There are {len(dirnames)} directories and {len(files)} images in '{root}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572f983e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train directory\n",
    "TRAIN_DIR = os.path.join(DIR_PATH,'train')\n",
    "\n",
    "#test directory\n",
    "TEST_DIR = os.path.join(DIR_PATH,'test')\n",
    "\n",
    "#val directory\n",
    "VAL_DIR = os.path.join(DIR_PATH,'valid')\n",
    "\n",
    "TRAIN_DIR, TEST_DIR, VAL_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57199fdb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#creating a list of all images\n",
    "img_list = list()\n",
    "\n",
    "for root, dirname, files in os.walk(DIR_PATH):\n",
    "    for file in files:\n",
    "        if file.endswith(\".jpg\"):\n",
    "            img_list.append((os.path.join(root, file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa201e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_list[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad1ce73",
   "metadata": {},
   "source": [
    "###  Random Image with size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d00600",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "\n",
    "random_path = random.choice(img_list)\n",
    "\n",
    "image = Image.open(random_path)\n",
    "label = os.path.dirname(random_path)\n",
    "label = os.path.basename(label)\n",
    "\n",
    "print(f'Height of Image| {image.height}')\n",
    "print(f'Width of Image| {image.width}')\n",
    "print(f'Path of Image| {random_path}')\n",
    "print(f'Class of Image| {label}')\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3219a6bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "\n",
    "random_list = []\n",
    "random_class = []\n",
    "\n",
    "for i in range(4):\n",
    "    p = random.choice(img_list)\n",
    "    random_list.append(p)\n",
    "    name = os.path.dirname(p)\n",
    "    name = os.path.basename(name)\n",
    "    random_class.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63969810",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "random_list,random_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9906634",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Random Images and their size\n",
    "for num in range(4):\n",
    "    with Image.open(random_list[num]) as f:\n",
    "        plt.figure(figsize = (4,4))\n",
    "        plt.imshow(f) \n",
    "        plt.title(f\"Class: {random_class[num]}\\nSize: {f.size}\")\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ffbf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform function for prepairing the images for neural network\n",
    "data_transform = transforms.Compose([\n",
    "    #resize the image\n",
    "    transforms.Resize(size=(64, 64)),\n",
    "    #Horizontal flip with .5 probability\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    #convert to Tensor\n",
    "    transforms.ToTensor() \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb27a7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#creation of Train Data and test data\n",
    "train_data = datasets.ImageFolder(root=TRAIN_DIR,\n",
    "                                  transform=data_transform, \n",
    "                                  target_transform=None)\n",
    "\n",
    "test_data = datasets.ImageFolder(root=TEST_DIR,\n",
    "                                transform=data_transform)\n",
    "\n",
    "print(f\"Train data:\\n{train_data}\\nTest data:\\n{test_data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7340c02b",
   "metadata": {},
   "source": [
    "### Before and after transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1c7fed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_transformed_images(image_paths, transform, n=3, seed=2):\n",
    "    \"\"\"Plots a series of random images from image_paths.\n",
    "\n",
    "    Will open n image paths from image_paths, transform them\n",
    "    with transform and plot them side by side.\n",
    "\n",
    "    Args:\n",
    "        image_paths (list): List of target image paths. \n",
    "        transform (PyTorch Transforms): Transforms to apply to images.\n",
    "        n (int, optional): Number of images to plot. Defaults to 3.\n",
    "        seed (int, optional): Random seed for the random generator. Defaults to 42.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    random_image_paths = random.sample(image_paths, k=n)\n",
    "    for image_path in random_image_paths:\n",
    "        with Image.open(image_path) as f:\n",
    "            fig, ax = plt.subplots(1, 2)\n",
    "            ax[0].imshow(f) \n",
    "            ax[0].set_title(f\"Original \\nSize: {f.size}\")\n",
    "            ax[0].axis(\"off\")\n",
    "\n",
    "            # Transform and plot image\n",
    "            # Note: permute() will change shape of image to suit matplotlib \n",
    "            # (PyTorch default is [C, H, W] but Matplotlib is [H, W, C])\n",
    "            transformed_image = transform(f).permute(1, 2, 0) \n",
    "            ax[1].imshow(transformed_image) \n",
    "            ax[1].set_title(f\"Transformed \\nSize: {transformed_image.shape}\")\n",
    "            ax[1].axis(\"off\")\n",
    "\n",
    "            fig.suptitle(f\"Class: {os.path.basename(os.path.dirname(image_path))}\", fontsize=16)\n",
    "\n",
    "plot_transformed_images(img_list, \n",
    "                        transform=data_transform, \n",
    "                        n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5820e36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#all the classes that can be determined\n",
    "class_names = train_data.classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0635a726-8502-4e2c-851a-601ace36be96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Iterable dataloaders to Create Batches of data to load into the model\n",
    "train_dataloader = DataLoader(dataset=train_data, \n",
    "                              batch_size=32, # how many samples per batch?\n",
    "                              num_workers=os.cpu_count()-1,# how many subprocesses to use for data loading? (higher = more)\n",
    "                              shuffle=True) # shuffle the data?\n",
    "\n",
    "test_dataloader = DataLoader(dataset=test_data, \n",
    "                             batch_size=1, \n",
    "                             num_workers=os.cpu_count()-1, \n",
    "                             shuffle=False) # don't usually need to shuffle testing data\n",
    "\n",
    "train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df54c4b1-1228-4f52-8b86-7cf126fc2ba1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img, label = next(iter(train_dataloader))\n",
    "\n",
    "#current image shape\n",
    "print(f\"Image shape: {img.shape} -> [batch_size, color_channels, height, width]\")\n",
    "print(f\"Label shape: {label.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4be335-2e52-4b16-aaf0-e24fb72249e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def display_random_images(dataset: torch.utils.data.dataset.Dataset,\n",
    "                          classes: [] = None,\n",
    "                          n: int = 10,\n",
    "                          display_shape: bool = True,\n",
    "                          seed: int = None):\n",
    "    \n",
    "    # Adjust display if n too high or else images will overlap\n",
    "    if n > 7:\n",
    "        n = 7\n",
    "        display_shape = False\n",
    "        print(\"For display purposes, n shouldn't be larger than 6, setting to 6 and removing shape display.\")\n",
    "    \n",
    "    #Set random seed to create reproducibility\n",
    "    if seed:\n",
    "        random.seed(seed)\n",
    "\n",
    "    #Get random sample indexes\n",
    "    random_samples_idx = random.sample(range(len(dataset)), k=n)\n",
    "\n",
    "    # Setup plot\n",
    "    plt.figure(figsize=(16, 10))\n",
    "\n",
    "    #Loop through samples and display random samples \n",
    "    for i, targ_sample in enumerate(random_samples_idx):\n",
    "        targ_image, targ_label = dataset[targ_sample][0], dataset[targ_sample][1]\n",
    "\n",
    "        #Adjust image tensor for plotting: [color_channels, height, width(pytoch)] -> [color_channels, height, width(matplotlib)]\n",
    "        targ_image_adjust = targ_image.permute(1, 2, 0)\n",
    "\n",
    "        # Plot adjusted samples\n",
    "        plt.subplot(1, n, i+1)\n",
    "        plt.imshow(targ_image_adjust)\n",
    "        plt.axis(\"off\")\n",
    "        if classes:\n",
    "            title = f\"class: {classes[targ_label]}\"\n",
    "        plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51078214-8f82-482f-a6ec-6004f5021242",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_random_images(train_data, \n",
    "                      n=7, \n",
    "                      classes=class_names,\n",
    "                      seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa288ca",
   "metadata": {},
   "source": [
    "## Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0192b7-0572-481c-89b2-81cafeea862e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Import the TinyVGG model \n",
    "from TinyVGG import tinyVGG\n",
    "\n",
    "model1 = tinyVGG(input_shape=3, # number of color channels (3 for RGB) \n",
    "                  hidden_units=10, #intermediate units\n",
    "                  output_shape=len(train_data.classes)).to(device) #output shape 10 in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9689d0-46ab-4531-a909-3b69c896aa2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ddccaa",
   "metadata": {},
   "source": [
    "###  Model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db15d1b-a6ef-4e40-9627-8f9835c0d2d1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#How each layer accepts and outputs the image\n",
    "from torchinfo import summary\n",
    "summary(model1, input_size=[1, 3, 64, 64])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcc6b05",
   "metadata": {},
   "source": [
    "## Train and test loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41de4178-72aa-4854-832d-3e93abddc59f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module, \n",
    "               dataloader: torch.utils.data.DataLoader, \n",
    "               loss_fn: torch.nn.Module, \n",
    "               optimizer: torch.optim.Optimizer):\n",
    "    # Put model in train mode\n",
    "    model.train()\n",
    "    \n",
    "    # Setup train loss and train accuracy values\n",
    "    train_loss, train_acc = 0, 0\n",
    "    \n",
    "    # Loop through data loader data batches\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Send data to target device\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # 1. Forward pass\n",
    "        y_pred = model(X)\n",
    "\n",
    "        # 2. Calculate and accumulate loss\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss.item() \n",
    "\n",
    "        # 3. Optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. Loss backward Tracking(autograd)\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. Optimizer step(making changes to the weigths)\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate and accumulate accuracy metric across all batches\n",
    "        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
    "        train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n",
    "\n",
    "    # Adjust metrics to get average loss and accuracy per batch \n",
    "    train_loss = train_loss / len(dataloader)\n",
    "    train_acc = train_acc / len(dataloader)\n",
    "    return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e03a359-48a8-47d8-8b77-c92f87270b1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_step(model: torch.nn.Module, \n",
    "              dataloader: torch.utils.data.DataLoader, \n",
    "              loss_fn: torch.nn.Module):\n",
    "    # Put model in eval mode\n",
    "    model.eval() \n",
    "    \n",
    "    # Setup test loss and test accuracy values\n",
    "    test_loss, test_acc = 0, 0\n",
    "    \n",
    "    # Turn on inference context manager this remove grad\n",
    "    with torch.inference_mode():\n",
    "        # Loop through DataLoader batches\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            # Send data to target device\n",
    "            X, y = X.to(device), y.to(device)\n",
    "    \n",
    "            # 1. Forward pass\n",
    "            test_pred_logits = model(X)\n",
    "\n",
    "            # 2. Calculate and accumulate loss\n",
    "            loss = loss_fn(test_pred_logits, y)\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            # Calculate and accumulate accuracy\n",
    "            test_pred_labels = test_pred_logits.argmax(dim=1)\n",
    "            test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
    "            \n",
    "    # Adjust metrics to get average loss and accuracy per batch \n",
    "    test_loss = test_loss / len(dataloader)\n",
    "    test_acc = test_acc / len(dataloader)\n",
    "    return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22885ec7-782c-4103-8401-103065e11534",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Take in various parameters required for training and test steps\n",
    "def train(model: torch.nn.Module, \n",
    "          train_dataloader: torch.utils.data.DataLoader, \n",
    "          test_dataloader: torch.utils.data.DataLoader, \n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          loss_fn: torch.nn.Module = torch.nn.CrossEntropyLoss(),\n",
    "          epochs: int = 20):\n",
    "    \n",
    "    #Create empty results dictionary\n",
    "    results = {\"train_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"test_loss\": [],\n",
    "        \"test_acc\": []\n",
    "    }\n",
    "    \n",
    "    #Loop through training and testing steps for a number of epochs\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss, train_acc = train_step(model=model1,\n",
    "                                           dataloader=train_dataloader,\n",
    "                                           loss_fn=loss_fn,\n",
    "                                           optimizer=optimizer)\n",
    "        test_loss, test_acc = test_step(model=model,\n",
    "            dataloader=test_dataloader,\n",
    "            loss_fn=loss_fn)\n",
    "        \n",
    "        #Print Results after each epoch\n",
    "        print(\n",
    "            f\"Epoch: {epoch+1} | \"\n",
    "            f\"train_loss: {train_loss:.4f} | \"\n",
    "            f\"train_acc: {train_acc:.4f} | \"\n",
    "            f\"test_loss: {test_loss:.4f} | \"\n",
    "            f\"test_acc: {test_acc:.4f}\"\n",
    "        )\n",
    "\n",
    "        #Update results dictionary\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"test_loss\"].append(test_loss)\n",
    "        results[\"test_acc\"].append(test_acc)\n",
    "\n",
    "    # 6. Return the filled results at the end of the epochs\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0e6f17",
   "metadata": {},
   "source": [
    "## Training of the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fd0f85-3a62-4e98-bed4-5c1cee9a39dc",
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42) \n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "# Set number of epochs\n",
    "NUM_EPOCHS = 1\n",
    "\n",
    "# Setup loss function and optimizer\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model1.parameters(), lr=0.001)\n",
    "\n",
    "# Start the timer\n",
    "from timeit import default_timer as timer \n",
    "start_time = timer()\n",
    "\n",
    "# Train model\n",
    "model_results = train(model=model1, \n",
    "                        train_dataloader=train_dataloader,\n",
    "                        test_dataloader=test_dataloader,\n",
    "                        optimizer=optimizer,\n",
    "                        loss_fn=loss_fn, \n",
    "                        epochs=NUM_EPOCHS)\n",
    "\n",
    "# End the timer and duration of training\n",
    "end_time = timer()\n",
    "print(f\"Total training time: {end_time-start_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393ca393-732b-42a8-8257-707a0534014e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80021d1e",
   "metadata": {},
   "source": [
    "## Loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627b9341-7114-43e6-9f83-1adc8f43b316",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_curves(results):\n",
    "    \"\"\"Plots training curves of a results dictionary.\n",
    "\n",
    "    Args:\n",
    "        results (dict): dictionary containing list of values, e.g.\n",
    "            {\"train_loss\": [...],\n",
    "             \"train_acc\": [...],\n",
    "             \"test_loss\": [...],\n",
    "             \"test_acc\": [...]}\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the loss values of the results dictionary (training and test)\n",
    "    loss = results['train_loss']\n",
    "    test_loss = results['test_loss']\n",
    "\n",
    "    # Get the accuracy values of the results dictionary (training and test)\n",
    "    accuracy = results['train_acc']\n",
    "    test_accuracy = results['test_acc']\n",
    "\n",
    "    # Figure out how many epochs there were\n",
    "    epochs = range(len(results['train_loss']))\n",
    "\n",
    "    # Setup a plot \n",
    "    plt.figure(figsize=(15, 7))\n",
    "\n",
    "    # Plot loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, loss, label='train_loss')\n",
    "    plt.plot(epochs, test_loss, label='test_loss')\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, accuracy, label='train_accuracy')\n",
    "    plt.plot(epochs, test_accuracy, label='test_accuracy')\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36096178-20ce-486a-b4e0-7a55bace2488",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_loss_curves(model_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd4f6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_img_list = list()\n",
    "\n",
    "for root, dirname, files in os.walk(VAL_DIR):\n",
    "    for file in files:\n",
    "        if file.endswith(\".jpg\"):\n",
    "            val_img_list.append((os.path.join(root, file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04532443",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_img_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f601c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_img_list(seed=42,\n",
    "                k=5):\n",
    "    random.seed(seed)\n",
    "    \n",
    "    val_random_path = random.choice(val_img_list)\n",
    "        \n",
    "    return val_random_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed5ba9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_random_path = predict_img_list(seed=42,\n",
    "                              k=5)\n",
    "val_random_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add13c17",
   "metadata": {},
   "source": [
    "## Prediction on random Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8458453a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "#read the image and convert that to tensor\n",
    "custom_image = Image.open(val_random_path)\n",
    "custom_image_resize = custom_image.resize((64,64),resample=0)\n",
    "trans = transforms.functional.pil_to_tensor(custom_image_resize).type(torch.float)\n",
    " \n",
    "    \n",
    "model1.eval()\n",
    "with torch.inference_mode():\n",
    "    val_image_pred = model1(trans.unsqueeze(dim=0).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032462e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_image_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddad654",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_image_pred_probs = torch.softmax(val_image_pred,dim=1)\n",
    "    \n",
    "    \n",
    "print(f\"Prediction probabilities: {val_image_pred_probs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd4f532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert prediction probabilities -> prediction labels\n",
    "val_image_pred_label= torch.argmax(val_image_pred_probs, dim=1)\n",
    "    \n",
    "    \n",
    "print(f\"Prediction label: {val_image_pred_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eeebc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_image_pred_class=class_names[val_image_pred_label.cpu()] # put pred label to CPU, otherwise will error\n",
    "val_image_pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94650eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_and_plot_image(model, \n",
    "                        image_path, \n",
    "                        class_names,\n",
    "                        device):\n",
    "    \"\"\"Makes a prediction on a target image and plots the image with its prediction.\"\"\"\n",
    "    \n",
    "    # 1. Load in image\n",
    "    target_image = Image.open(image_path)\n",
    "    \n",
    "    # 2. Resizing the image\n",
    "    custom_image_resize = custom_image.resize((64,64),resample=0)\n",
    "    \n",
    "    # 3. Convert the image to tensor\n",
    "    trans = transforms.functional.pil_to_tensor(custom_image_resize).type(torch.float)\n",
    "    \n",
    "    # 4. Make sure the model is on the target device\n",
    "    model.to(device)\n",
    "    \n",
    "    # 5. Turn on model evaluation mode and inference mode\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        # Add an extra dimension to the image\n",
    "        target_image = target_image.unsqueeze(dim=0)\n",
    "    \n",
    "        # Make a prediction on image with an extra dimension and send it to the target device\n",
    "        target_image_pred = model(target_image.to(device))\n",
    "        \n",
    "    # 6. Convert logits -> prediction probabilities (using torch.softmax() for multi-class classification)\n",
    "    target_image_pred_probs = torch.softmax(target_image_pred, dim=1)\n",
    "\n",
    "    # 7. Convert prediction probabilities -> prediction labels\n",
    "    target_image_pred_label = torch.argmax(target_image_pred_probs, dim=1)\n",
    "    \n",
    "    # 8. Plot the image alongside the prediction and prediction probability\n",
    "    plt.imshow(target_image.squeeze().permute(1, 2, 0)) # make sure it's the right size for matplotlib\n",
    "    img = np.asarray(Image.open(image_path))\n",
    "    plt.imshow(img)\n",
    "    if class_names:\n",
    "        title = f\"Pred: {class_names[target_image_pred_label.cpu()]} | Prob: {target_image_pred_probs.max().cpu():.3f}\"\n",
    "    else: \n",
    "        title = f\"Pred: {target_image_pred_label} | Prob: {target_image_pred_probs.max().cpu():.3f}\"\n",
    "    plt.title(title)\n",
    "    plt.axis(False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8427198a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_and_plot_image(model=model1,\n",
    "                    image_path=val_random_path,\n",
    "                    class_names=class_names,\n",
    "                    device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fc6b26",
   "metadata": {},
   "source": [
    "## Validation Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586d5ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data = datasets.ImageFolder(root=VAL_DIR,\n",
    "                                transform=data_transform)\n",
    "\n",
    "valid_dataloader = DataLoader(dataset=valid_data, \n",
    "                             batch_size=5, \n",
    "                             num_workers=1, \n",
    "                             shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de104d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader):\n",
    "    model1.eval()\n",
    "    with torch.inference_mode():\n",
    "        total, correct = 0, 0\n",
    "        for data in dataloader:\n",
    "            # Get the inputs and move them to the device\n",
    "            img, label = next(iter(dataloader))\n",
    "            img, label = img.to(device), label.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(img)\n",
    "            predicted = torch.softmax(outputs,dim=1)\n",
    "            predicted = torch.argmax(outputs, dim=1)\n",
    "\n",
    "            # Record the accuracy\n",
    "            total += label.size(0)\n",
    "            correct += (predicted == label).sum().item()\n",
    "\n",
    "    # Print the accuracy\n",
    "    print(f'Accuracy of the model on the {total} images: {100*correct/total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264aab1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Valid Case')\n",
    "# Evaluate valid data\n",
    "\n",
    "evaluate(model1, valid_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09ad497",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b4b280",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model1.state_dict(),'Best_model/tinyvgg/model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tiger",
   "language": "python",
   "name": "tiger"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
